{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4IENoadf1kRH5hoz7PJxv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raphaelrcb/HuggingFace_Workshop/blob/main/Notebooks/HuggingFace_getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizagem Com HuggingFace"
      ],
      "metadata": {
        "id": "DHcC54BY5tB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eqypvTI5S4cJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fuqfQYw85fGk"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eit8U53qTGd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sI55RRX2TGXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando a biblioteca Transformers e a fun√ß√£o Pipeline"
      ],
      "metadata": {
        "id": "ri-Kpw1fW0co"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An√°lise de Sentimento\n",
        "Atrav√©s da Pipeline √© poss√≠vel fazer a An√°lise de Sentimento de um trecho de texto, dizendo se o texto √© positivo ou negativo e a sua confian√ßa. Se n√£o especificado, o classificador carrega um modelo pr√©-treinado padr√£o (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english), e seu *tokeneizer*\n"
      ],
      "metadata": {
        "id": "xOi37N6gb2Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lqcuUtkuWpQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"We will be champions tonight\")"
      ],
      "metadata": {
        "id": "QlgT-AcvXC5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"They broke up\")"
      ],
      "metadata": {
        "id": "K4Y_-HooXo0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"They broke up, now I have a chance to go out with her\")"
      ],
      "metadata": {
        "id": "I5mOgXPxXtal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = classifier([\"We are very happy to show you the ü§ó Transformers library.\", \"We hope you don't hate it.\"])\n",
        "for result in results:\n",
        "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n"
      ],
      "metadata": {
        "id": "KKuXXczmYMmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterando por datasets\n",
        "\n",
        "A fun√ß√£o pipeline() tamb√©m pode iterar atrav√©s dos datasets para alguma tarefa necess√°ria. Utilizando reconhecimento de fala autom√°tido por exemplo, √© importante carregar o dataset de √°udios para que seja poss√≠vel utilizar no c√≥digo. Carregaremos o [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)"
      ],
      "metadata": {
        "id": "WZYd_sPIcKqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FRLWM2TFcv6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "√â necess√°rio garantir que a taxa de amostragem do dataset corresponde √† taxa de amostragerm do modelo em que foi treinado, no caso: model=\"facebook/wav2vec2-base-960h\""
      ],
      "metadata": {
        "id": "YEuM7YqDgeKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AuokhQyMdKxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
      ],
      "metadata": {
        "id": "DSoZHgIGgdm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = speech_recognizer(dataset[3:7][\"audio\"])\n",
        "print([d[\"text\"] for d in result])"
      ],
      "metadata": {
        "id": "1u9lpY4Dd4-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizar outro modelo e _tokenizer_ na pipeline\n",
        "a pipeline consegue acomodar qualquer modelo do Hub, sendo f√°cil de adaptar a pipeline para outros casos de uso. Por exemplo, utilizar um modelo que po√ßa usar outra l√≠ngua."
      ],
      "metadata": {
        "id": "eGHrbQ1vdeQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\""
      ],
      "metadata": {
        "id": "30unzT6gdo6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilize <u>AutoModelForSequenceClassification</u> e <u>AutoTokenizer</u> para carregar um modelo pr√©-treinado e seu _tokenizer_ associado.\n",
        "\n"
      ],
      "metadata": {
        "id": "68zSA1mUi_An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "8XD5R91oj5Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "classifier([\"Flamengo √© o maior do mundo.\", \"No puedo creer que el Real Madrid haya perdido ante el Flamengo.\", \"Flamengo is world Champion\"])"
      ],
      "metadata": {
        "id": "pxcjLUDOkDn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repetindo com o TensorFlow e outro modelo"
      ],
      "metadata": {
        "id": "tKsT4MYamoP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "mbggWLJ2msnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "classifier([\"Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.\", \"I hate this\", \"Yo no creo que ella es tan maligna\", \"FLAMENGO CAMPE√ÉO\"])"
      ],
      "metadata": {
        "id": "Shs8kKComv9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoClass\n",
        "\n",
        "Uma <u>Autoclass</u> √© um atalho que automaticamente busca a arquitetura de um modelo pr√©-treinado dado seu nome ou caminho. S√≥ √© necess√°rio selecionar o Autoclass apropriada para a sua tarefa e classe de pr√©-processamento associada. Utilizando o exemplo anterior para replicar o resultado da pipeline():\n",
        "\n",
        "\n",
        "## AutoTokenizer\n",
        "\n",
        "Um _tokenizer_ √© respons√°vel por pr√©processar um texto em um _array_ de n√∫meros como entradas de um modelo. Existem diversas regras que fazem parte de um processo de _tokeniza√ß√£o_, incluindo como separar a palavra e at√© qual n√≠vel as palavras devem ser separadas. O mais importante √© lembrar que √© necess√°rio instanciar o _tokenizer_ com o mesmo nome de modelo para garantir que est√° sendo usado o mesmo processo de _tokeniza√ß√£o_ que o modelo foi pr√©-treinado.\n",
        "\n",
        "\n",
        " https://huggingface.co/docs/transformers/en/tokenizer_summary\n",
        "\n"
      ],
      "metadata": {
        "id": "hR6uZC2pFYfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregando um tokenizer com o AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\"\n",
        "#model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "DTzIDuKQHKFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Passando um texto para o tokenizer\n",
        "encoding = tokenizer(\"Flamengo √© o maior do mundo.\")\n",
        "print(encoding)"
      ],
      "metadata": {
        "id": "w7hH5jhOH5Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O tokenizer pode retornar um dicion√°rio contendo:\n",
        "\n",
        "\n",
        "*   <u>input_ids</u>: representa√ß√µes num√©ricas dos tokens\n",
        "*   <u>attention_masks</u>: Indica quais tokens devem ser atendidos\n",
        "\n",
        "O tokenizer tamb√©m aceita um lista de entradas, preenchendo e truncando o texto para retornart um lote com tamanho uniforme\n"
      ],
      "metadata": {
        "id": "ahmSgvH1Je7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Com PyTorch\n",
        "pt_batch = tokenizer(\n",
        "    [\"Flamengo √© o maior do mundo.\", \"No puedo creer que el Real Madrid haya perdido ante el Flamengo.\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "print(pt_batch)"
      ],
      "metadata": {
        "id": "mDiLgWi8JenL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repetindo para o modelo Com TensorFlow\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "tf_batch = tokenizer(\n",
        "    [\"Flamengo √© o maior do mundo.\", \"No puedo creer que el Real Madrid haya perdido ante el Flamengo.\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"tf\",\n",
        ")\n",
        "print(tf_batch)\n"
      ],
      "metadata": {
        "id": "80EBCfpgKY6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoModel\n",
        "\n",
        "Transformers entrega uma forma simples e unificada de carregar inst√¢ncias pr√©-treinadas. Isso significa que carregar um <u>AutoModel</u> parece como carregar um <u>AutoTokenizer</u>. A √∫nica diferen√ßa √© selecionar o  <u>AutoModel</u> correto para a tarefa. Para classifica√ß√£o de texto (ou de sequ√™ncia), deve-se carregar o  <u>AutoModelForSequenceClassification</u>"
      ],
      "metadata": {
        "id": "FAtJAaIJKqfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\"\n",
        "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "55Yc2RTML9Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Para passar o lote pr√©-processado de entradas diretamente no modelo, deve-se apenas desenpacotar o dicion√°rio adicionando **\n",
        "# com PyTorch\n",
        "pt_outputs = pt_model(**pt_batch)\n",
        "print(pt_outputs)"
      ],
      "metadata": {
        "id": "yqTBhL4nL_TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo tem a sa√≠da das ativa√ß√µes finais no atributo `logits`. Aplicando a fun√ß√£o softmax, se recebe as probabilidades.:"
      ],
      "metadata": {
        "id": "QD2U9DdLO3Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
        "print(pt_predictions)"
      ],
      "metadata": {
        "id": "f_tnJ7WgOuRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repetindo para o TensorFlow\n",
        "\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "## e passando o lote pr√©processado direto para o modelo. Voc√™ pode passar o tensor como √©\n",
        "\n",
        "tf_outputs = tf_model(tf_batch)\n",
        "print(tf_outputs)"
      ],
      "metadata": {
        "id": "EzOkIEqpPOeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo tem a sa√≠da das ativa√ß√µes finais no atributo `logits`. Aplicando a fun√ß√£o softmax, se recebe as probabilidades.:"
      ],
      "metadata": {
        "id": "Vo_36lDIP_yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n",
        "tf_predictions"
      ],
      "metadata": {
        "id": "33cW9EiBQHLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvar um Modelo"
      ],
      "metadata": {
        "id": "gAbTgOYCWbg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "## Uma vez que seu modelo est√° pronto √© poss√≠vel salv√°-lo junto de seu tokenizer usando PreTRainedModel.save_pre_trained()\n",
        "\n",
        "pt_save_directory = \"./pt_save_pretrained\"\n",
        "tokenizer.save_pretrained(pt_save_directory)\n",
        "pt_model.save_pretrained(pt_save_directory)"
      ],
      "metadata": {
        "id": "zOulaGL7QIS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# E pode carreg√°-lo novamente com AutoModelForSequenceClassification.from_pretrained()\n",
        "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
      ],
      "metadata": {
        "id": "6s-BadeoXkYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para o TensorFlow\n",
        "## Uma vez que seu modelo est√° pronto √© poss√≠vel salv√°-lo junto de seu tokenizer usando TFPreTRainedModel.save_pre_trained()\n",
        "\n",
        "tf_save_directory = \"./tf_save_pretrained\"\n",
        "tokenizer.save_pretrained(tf_save_directory)\n",
        "tf_model.save_pretrained(tf_save_directory)"
      ],
      "metadata": {
        "id": "FGeVpr9OXvGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# E pode carreg√°-lo novamente com AutoModelForSequenceClassification.from_pretrained()\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")"
      ],
      "metadata": {
        "id": "X-6hNieLX9Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma caracter√≠stica interessante dos Transformers √© a habilidade de salvar e recarregar um modelo tanto como PyTorch ou TensorFlow. o par√¢metro `from__pt` e `from_tf` consegue fazer essa convers√£o\n"
      ],
      "metadata": {
        "id": "O81tDtLMYGQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n",
        "pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)\n",
        "\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)"
      ],
      "metadata": {
        "id": "g3v7cXtoYFcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos Customizados\n",
        "\n",
        "√â poss√≠vel modificar e customizar a classe de configura√ß√£o de modelos para mudar como ele √© constru√≠do. A configura√ß√£o especif√≠ca os atributos do modelo, como o n~umero de camadas ocultas ou _attention heads_. Se come√ßa do zero quando se inicializa um modelo de uma configura√ß√£o de classe customizada. Os atributos do modelos s√£o inicializados aleat√≥riamente e deve-se treinar o modelo antes de ser usado para conseguir resultados.\n",
        "\n",
        "Inicia-se importanto o AutoConfig e ent√£o carregando o modelo pr√©-treinado que se deseja modificar. Dentro de `AutoConfig.from_pretrained()` √© poss√≠vel especificar o atributo que se deseja mudar."
      ],
      "metadata": {
        "id": "wnntN5GSYwMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "custom_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)"
      ],
      "metadata": {
        "id": "8NRaGm9hYv-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "## Criar um modelo da sua configura√ß√£o customizada com AutoModel.from_config()\n",
        "\n",
        "from transformers import AutoModel\n",
        "\n",
        "custom_model = AutoModel.from_config(custom_config)\n"
      ],
      "metadata": {
        "id": "Gm4ZyVRA_UJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow\n",
        "## Criar um modelo da sua configura√ß√£o customizada com TFAutoModel.from_config()\n",
        "\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "custom_tf_model = TFAutoModel.from_config(custom_config)\n"
      ],
      "metadata": {
        "id": "YpLf5iIm_q9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mais informa√ß√µes criando um modelo customizado, d√™ uma olhada em [Criando uma arquitetura customizada](https://huggingface.co/docs/transformers/en/create_a_model)."
      ],
      "metadata": {
        "id": "HffwHhq8AUg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando - um loop de treinamento - otimizador no PyTorch\n",
        "\n",
        "Todos os modelos s√£o padr√£o `torch.nn.Module` ent√£o pode-se utiliz√°-los em qualquer loop de treinamento. Enquanto √© poss√≠vel escrever o pr√≥prio loop de treinamento, os _Transformers_ fornecem uma classe <u>Trainer</u> de treinamento, que cont√™m o loop de treinamento b√°sico e que adiciona funcionalidades adicionais para catacter√≠sticas como treinamento distribu√≠do, precis√£o mista e mais.\n",
        "\n",
        "\n",
        "Dependendo da tarefa, tipicamente se passa os seguintes par√¢metros para o <u>Trainer</u>\n"
      ],
      "metadata": {
        "id": "QqaZaa9mAznz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Come√ßando com um <u>PreTrainedModel</u> ou um `torch.nn.Module`"
      ],
      "metadata": {
        "id": "QvEHC0DBCUK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "0k3Nb6X5AxdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. <u>TrainingArguments</u> cont√™m os h√≠per-par√¢metros que podem ser alterados, como taxa de aprendizado, tamanho do lote, n√∫meros de _epochs_ para treinamento. Se n√£o se especificam os valores, os padr√µes s√£o utilizados."
      ],
      "metadata": {
        "id": "tYFOH7ZxCuyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"path/to/save/folder/\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        ")"
      ],
      "metadata": {
        "id": "ZQFpntT7DM71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Carrega uma classe de pr√©-processamento como _tokenizer_, _image processor_, _feature extractor_, ou _processor_:"
      ],
      "metadata": {
        "id": "0ymPpfxeDNdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "jOXAJfo3DKRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Carregar um Dataset."
      ],
      "metadata": {
        "id": "14djQCVkEO73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT"
      ],
      "metadata": {
        "id": "EaOSAbMtETtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Criar uma fun√ß√£o para _tokenizar_ o dataset e aplique o _dataset_ inteiro com <u>map</u>"
      ],
      "metadata": {
        "id": "5vR9J0w0EWNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(dataset):\n",
        "    return tokenizer(dataset[\"text\"])\n",
        "\n",
        "\n",
        "dataset = dataset.map(tokenize_dataset, batched=True)"
      ],
      "metadata": {
        "id": "RlfVaadnEe5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Um <u>DataCollatorWithPadding</u> para criar um lote de exemplos para o seu dataset"
      ],
      "metadata": {
        "id": "aS5VL1zpEjLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "kTCN7j2LE-Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E junte todas essas classes em um <u>Trainer</u>"
      ],
      "metadata": {
        "id": "OOJi3hkGFFHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")  # doctest: +SKIP"
      ],
      "metadata": {
        "id": "zyr7lXWSFLOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E quando estiver pronto, chame <u>train()</u> para iniciar o treinamento:"
      ],
      "metadata": {
        "id": "Jw2MZ6qFFRE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "I7VVJwSdFZus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Para tarefas - como tradu√ß√£o e sumariza√ß√£o - que utilizam modelo sequ√™ncia a sequ√™ncia, usa-se no lugar as classes <u>Seq2SeqTrainer</u> <u>Seq2SeqTrainingArguments</u>.\n",
        "\n",
        "---\n",
        "\n",
        "pode-se customizar o comportamento do loop de treinamento por <u>_subclassing_</u> os m√©todos de <u>Trainer</u>. Isso permite que se customize caracter√≠sticas como fun√ß√£o de perda, otimizador e agendador. Isso pode ser visto com mais detalhes na documenta√ß√£o de [Trainer](https://huggingface.co/docs/transformers/v4.44.2/en/main_classes/trainer#transformers.Trainer) para quais m√©todos podem ser <u>subclasses</u>."
      ],
      "metadata": {
        "id": "DDFUIlHoFb8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando - com TensorFlow\n",
        "\n",
        "Todos os modelos s√£o padr√£o `tf.keras.Model` ent√£o podem ser treinados com <u>TensorFLow</u> utilizando a API <u>Keras</u>. _Transformers_ prov√™m o m√©todo <u>prepare_tf_dataset()</u> para carregar seu dataset simplesmente como `tf.data.Dataset` ent√£o √© poss√≠vel come√ßar o treinamento imediatamente com o compilador Keras e m√©todos <u>fit</u>\n",
        "\n",
        "\n",
        "Dependendo da tarefa, tipicamente se passa os seguintes par√¢metros para o <u>Trainer</u>\n"
      ],
      "metadata": {
        "id": "_jhofTTfI482"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Come√ßando com um <u>TFPreTrainedModel</u> ou um `tf.keras.Model`"
      ],
      "metadata": {
        "id": "ZPceP2GhI483"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "KV2uCiYxI483"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Carrega uma classe de pr√©-processamento como _tokenizer_, _image processor_, _feature extractor_, ou _processor_:"
      ],
      "metadata": {
        "id": "20utINtDI483"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "lxPsNIYQI484"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Criar uma fun√ß√£o para _tokenizar_ o dataset"
      ],
      "metadata": {
        "id": "qp71JUDDI484"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(dataset):\n",
        "    return tokenizer(dataset[\"text\"])  # doctest: +SKIP"
      ],
      "metadata": {
        "id": "qDf-S646I484"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Aplique o _tokenizer_ pelo dataset inteiro com <u>map</u> e ent√£o passe o dataset e o tokenizer para <u>prepare_tf_dataset()</u>. √â poss√≠vel mudar o tamanho do lote e embaralhar o dataset se preferir."
      ],
      "metadata": {
        "id": "Oj-0sicDI484"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP\n",
        "tf_dataset = model.prepare_tf_dataset(\n",
        "    dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer\n",
        ")  # doctest: +SKIP"
      ],
      "metadata": {
        "id": "VXw4MLHJI484"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Quando estiver pronto, chame o `compile` e o `fit` para iniciar o treinamento. Nota-se que todos os modelos Transformers t√™m uma fun√ß√£o _task-relevant_ padr√£o de fun√ß√£o de perda, ent√£o n√£o √© necess√°rio especificar um."
      ],
      "metadata": {
        "id": "ceRnfXIzLNYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer='adam')  # No loss argument!\n",
        "model.fit(tf_dataset)  # doctest: +SKIP"
      ],
      "metadata": {
        "id": "h9Qwh9mKLuMe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}